// The art of compromise

AI in the broadest sense

What is an AI?

You may say, well, AI is natural language processing, image recongition, data analysis, drug discovery... These answers are all correct, but they sound a little bit boring, because they imply that AIs can only do narrow and specific tasks, and that it is not practical to expect AIs to be as strong as human beings in terms of the word "intelligence".

In fact, people once had much wilder dreams about what "AI" means, and famous computer scientists like John McCarthy believed that human-level intelligence will eventually come out. This kind of hypothesized AI was then renamed to be "argificial general intelligence" or "AGI", to make way for the booming narrow AIs that are mostly implemented using machine learning or deep learning approaches.

So, why don't we temporarily jump out of the hustle and bustle of narrow AIs, and think about the word "AI" in the broadest sense?

# What is intelligence?
This is a tricky question because people differ in opinion on how intelligence should be defined. Some think that computers are intelligent because they are fast in calculation and help solve people's problems, but others think that computers are not intelligent because they execute exactly what programmers wrote and do not have their own ideas.

Those who have high expectations on what intelligence is are hard to satisfy. People once thought that only machines with intelligence can beat human players in chess, but when Deep Blue came out, they said it was just a search algorithm. Then they thought human beings are unbeatable in Go game because rule-based search algorithms no longer work, but when AlphaGo came out, they said it was also just "brute force". When ChatGPT came out, though it is much more general-purpose and passes Turing tests easily, they said it is just imitating what it is trained on and does not have anything of its own.

Then when you ask these people how intelligence is supposed to be implemented, they are likely to say, "I don't know, but I know intelligence is definitely not blablabla...". This is a problem of our own: we have an implicit assumption that only we human beings can have true intelligence but not anything we can come up with that we know their working principles. This is also a part of reason why we tend to resort to fuzzy algorithms like neural network, because we cannot clearly see what is going on in it, and cannot manipulate it precisely. Brains are fuzzy. Neural nets are fuzzy. Bam! They are the same thing! However, I personally don't think we should trade logic for fuzziness only because our brains are fuzzy.

In my opinion, the definition of intelligence is not that important in a practical sense, because what we urgently need is a machine that solves our problems, whether it is implemented with true intelligence or not. Alan Turing claimed that as long as an AI acts like a human being, it is intelligent. This is a practical definition, since we can then model intelligence ourselves in whatever ways we want as long as it solves the problem, and start our work immediately. But there is a problem. "Acting like a human being", as we see now with ChatGPT, is not enough for every problem we expect AI to solve. After all, if you give ChatGPT a prompt "You are an advanced spacecraft engineer. Now build me a spacecraft", you won't expect ChatGPT to imitate an engineer well enough to really build a spacecraft for you. Turing reduction does not work here, according to our common sense.

So, I think the proper practical definition of intelligence should be the ability to solve our problems. The harder and more comprehensive a problem an AI can solve, the more intelligent that AI is.

# What are the problems?
So, what are the problems? There are tons of problems we want AI to solve; the sky is the limit. Let me just mention a few. I am not good at academics, so I would like an AI to write the courseworks for me. I am not good at sports, so I want an AI robot to play tennis and badminton against my opponents on my behalf. I don't want to clean the house and cook by myself, so I want an AI robot to do all these for me. As for occupations like delivery men, waiters, construction site workers, they are better replaced by AI so that human beings do not have to live a hard life.

Now you may find something. If the problems we want to solve are all related to us, why don't we just build a "human being" that knows our convention, has our knowledge and ability, and can physically impact the world just like us? If we can do that, we are able to solve all the problems once and for all.

# General Intelligence
There are different opinions on how "smart" an AI can become. Some think that AIs are going to have much greater intelligence than human beings so that they are going to perceive ideas not understandable by human beings, and may eliminate human beings for some noble purposes. Some think that AIs will be smarter than human beings, can invent things that humans cannot invent, and can even write AIs that are smarter than themselves. Some think that scientists can invent AIs that are as smart as human beings, but not smarter, since the only source of intelligence comes from human beings. And some pessimistic people think that human level intelligence cannot be reached but only be approached. 

As for me, I was once super optimistic about general intelligence but then became pessimistic. The reason will be shown in the following chapters. Nevertheless, no matter what we believe, we can come to consensus that a smarter AI is not easier to make than a dumber AI. While it is nice to dream for the ultimate kind of AI, it is more practical to start at a lower starting point, since a breakthrough from 0 to 1 is more exciting than an improvement from smart to even smarter.

# Practical General Intelligence: Comprehensive Servant for Human Beings
So, what about letting a general AI to start working for us first? No need for conscious, emotion, self-awareness, identity, or purpose of life. I think this is a reasonably low starting point, and this will be the goal we try to achieve in this website.

<!-- A human being has various forms of intelligence, for example, the ability to do math problems, the ability to do sports, the ability to recognize 3D object, and the ability to manufacture products. If we want to build a general intelligence like a human being, we need to first identify the range of abilities that an AI should have, and describe it using as few sentences as possible. 
People argue about whether there is a unified algorithm that solves all tasks at once,  -->
<!-- 
// Problem seems not unified; different problem different strategies
// neural networks are good at dealing with subjective problems, while ... -->